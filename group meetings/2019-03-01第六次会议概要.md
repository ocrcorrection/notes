# 2019-03-02 小组会第六次会议概要

## 计划

1. 论文交流（上次因时间紧张，未完成，这次交流下）
2. 代码交流，把整个项目架构框架理清，知道是各个部分是怎么实现的
3. 进一步研究进展讨论
4. 数据详细看下



## 下一步工作计划

### **源码实现**

#### **数据部分** python2

> 熊，
>
> argparse的使用
>
> 模型需要的相关数据生成

data_generate_train_noisy.py

data_generate_train_synthetic.py

data_processing.py

data_tokenize.py



#### **模型部分** python 3

decode.py

flag.py

model.py

model_attn.py

train.py

utils.py

### 论文把能写的部分写完

> abstract 
>
> introduction
>
> related work
>
> method
>
> experiments
>
> results

- 之前OCR部分的实验写（experiments，methods）
- 已经看到的一些论文，总结（related work）
- 该论文实验做完之后，下一步要做的实验（experiments）
- 下一步打算使用的方法（methods）

### docker得重新建

已完成，和原先一样

## 问题

- [x] **vocabulary：**词汇表

  之所以按照从高到低，可能是为了后期的特征选取

- [x] **voc_size：**one-hot编码长度

- [x] **函数pair_iter：**数据+标签

  每一对数据的迭代器

- [ ] **model_attn:**

- [ ] **模型训练的一些中间产物**

## 小结

### **针对中文数据**

- **原始数据（图片，pdf）**
- **对于原始数据，进行第一步OCR识别**

- **中文witnesses寻找**

- **witnesses的来源，可以是之前OCR成果的checkpoint；或者是目前主流的其他OCR系统的扫描结果**

  > **witnesses**的寻找很重要；
  >
  > 后期可以考虑使用切字方法；
  >
  > 长度，编辑距离选择；
  >
  > 结合NLP， 词性，语义信息



